{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Recommendation System Using Machine Learning\n",
    "## Using Soil and Climate Data\n",
    "\n",
    "This notebook builds a machine learning model to recommend the most suitable crop based on:\n",
    "- **N** (Nitrogen in soil)\n",
    "- **P** (Phosphorus in soil)\n",
    "- **K** (Potassium in soil)\n",
    "- **Temperature**\n",
    "- **Humidity**\n",
    "- **pH** (Soil acidity)\n",
    "- **Rainfall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data1 = pd.read_csv('Datasets/crop_data1.csv')\n",
    "data2 = pd.read_csv('Datasets/crop_data2.csv')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check for Missing Values and Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for each feature\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Distribution of Features', fontsize=16, fontweight='bold')\n",
    "\n",
    "features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    axes[idx].hist(data[feature], bins=30, color='skyblue', edgecolor='black')\n",
    "    axes[idx].set_title(f'{feature} Distribution')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Data distributions visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Unique Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique crops\n",
    "unique_crops = data['label'].unique()\n",
    "print(f\"Number of unique crops: {len(unique_crops)}\")\n",
    "print(f\"\\nCrops available: {sorted(unique_crops)}\")\n",
    "\n",
    "# Count of each crop\n",
    "print(\"\\nCrop distribution:\")\n",
    "print(data['label'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = data['label']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\n‚úì Data preprocessed and scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set: {X_train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Multiple ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# 1. Gaussian Naive Bayes\n",
    "print(\"Training Gaussian Naive Bayes...\")\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "models['Gaussian Naive Bayes'] = gnb\n",
    "results['Gaussian Naive Bayes'] = accuracy_gnb\n",
    "print(f\"‚úì Accuracy: {accuracy_gnb:.4f}\\n\")\n",
    "\n",
    "# 2. Decision Tree\n",
    "print(\"Training Decision Tree...\")\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "models['Decision Tree'] = dt\n",
    "results['Decision Tree'] = accuracy_dt\n",
    "print(f\"‚úì Accuracy: {accuracy_dt:.4f}\\n\")\n",
    "\n",
    "# 3. Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "models['Random Forest'] = rf\n",
    "results['Random Forest'] = accuracy_rf\n",
    "print(f\"‚úì Accuracy: {accuracy_rf:.4f}\\n\")\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "print(\"Training Support Vector Machine...\")\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "models['SVM'] = svm\n",
    "results['SVM'] = accuracy_svm\n",
    "print(f\"‚úì Accuracy: {accuracy_svm:.4f}\\n\")\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "print(\"Training Gradient Boosting...\")\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "models['Gradient Boosting'] = gb\n",
    "results['Gradient Boosting'] = accuracy_gb\n",
    "print(f\"‚úì Accuracy: {accuracy_gb:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"All models trained successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\nüèÜ MODEL PERFORMANCE COMPARISON\\n\")\n",
    "print(\"-\" * 40)\n",
    "for model_name, accuracy in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model_name:.<25} {accuracy:.2%}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Best model\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model = models[best_model_name]\n",
    "best_accuracy = results[best_model_name]\n",
    "\n",
    "print(f\"\\n‚úì BEST MODEL: {best_model_name}\")\n",
    "print(f\"‚úì Accuracy: {best_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "models_list = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "\n",
    "colors = ['#2ecc71' if acc == max(accuracies) else '#3498db' for acc in accuracies]\n",
    "bars = plt.bar(models_list, accuracies, color=colors, edgecolor='black', linewidth=2)\n",
    "\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim([0.9, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "             f'{acc:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Classification Report for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Classification Report for {best_model_name}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict crop for specific soil and climate conditions\n",
    "def predict_crop(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    \"\"\"\n",
    "    Predict the best crop for given environmental conditions\n",
    "    \"\"\"\n",
    "    # Create input data\n",
    "    input_data = np.array([[N, P, K, temperature, humidity, ph, rainfall]])\n",
    "    \n",
    "    # Scale the input\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Predict using best model\n",
    "    prediction = best_model.predict(input_scaled)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Test predictions\n",
    "print(\"\\nüåæ CROP PREDICTION EXAMPLES\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example 1: High nitrogen, good rainfall\n",
    "predicted_crop_1 = predict_crop(N=90, P=42, K=43, temperature=20.87, humidity=82.0, ph=6.5, rainfall=202.9)\n",
    "print(f\"\\nConditions: High N, High humidity, Good rainfall\")\n",
    "print(f\"Predicted Crop: {predicted_crop_1}\")\n",
    "\n",
    "# Example 2: Dry conditions\n",
    "predicted_crop_2 = predict_crop(N=30, P=25, K=35, temperature=35.0, humidity=45.0, ph=7.0, rainfall=50.0)\n",
    "print(f\"\\nConditions: Low N, Low humidity, Low rainfall\")\n",
    "print(f\"Predicted Crop: {predicted_crop_2}\")\n",
    "\n",
    "# Example 3: Medium conditions\n",
    "predicted_crop_3 = predict_crop(N=60, P=35, K=40, temperature=25.0, humidity=65.0, ph=6.8, rainfall=120.0)\n",
    "print(f\"\\nConditions: Medium N, Medium humidity, Medium rainfall\")\n",
    "print(f\"Predicted Crop: {predicted_crop_3}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Feature Importance (for Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "feature_names = ['N', 'P', 'K', 'Temperature', 'Humidity', 'pH', 'Rainfall']\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\nüìä FEATURE IMPORTANCE (Random Forest)\\n\")\n",
    "print(\"-\" * 40)\n",
    "for i, idx in enumerate(indices, 1):\n",
    "    print(f\"{i}. {feature_names[idx]:.<20} {importances[idx]:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(indices)), importances[indices], color='#3498db', edgecolor='black')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Feature Importance in Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROP RECOMMENDATION SYSTEM - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä DATASET INFORMATION:\n",
    "  ‚Ä¢ Total Samples: {len(data)}\n",
    "  ‚Ä¢ Features: 7 (N, P, K, Temperature, Humidity, pH, Rainfall)\n",
    "  ‚Ä¢ Target Classes: {len(unique_crops)} crops\n",
    "\n",
    "üìà MODEL PERFORMANCE:\n",
    "  ‚Ä¢ Best Model: {best_model_name}\n",
    "  ‚Ä¢ Accuracy: {best_accuracy:.2%}\n",
    "  ‚Ä¢ Test Set Size: {len(X_test)} samples\n",
    "\n",
    "üéØ KEY FEATURES:\n",
    "  ‚Ä¢ Preprocessed features using StandardScaler\n",
    "  ‚Ä¢ Trained 5 different ML algorithms\n",
    "  ‚Ä¢ Evaluated using accuracy and classification metrics\n",
    "  ‚Ä¢ Made predictions on new environmental conditions\n",
    "\n",
    "üí° INSIGHTS:\n",
    "  ‚Ä¢ Most important feature: {feature_names[indices[0]]}\n",
    "  ‚Ä¢ Can predict crop type with {best_accuracy:.2%} confidence\n",
    "  ‚Ä¢ Model is ready for deployment\n",
    "\n",
    "‚úÖ PROJECT COMPLETE!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
